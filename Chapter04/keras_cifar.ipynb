{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll download the dataset first:"
      ],
      "metadata": {
        "id": "-h2cwJZ4COZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train, Y_train), (X_validation, Y_validation) = cifar10.load_data()\n",
        "\n",
        "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
        "Y_validation = keras.utils.to_categorical(Y_validation, 10)"
      ],
      "metadata": {
        "id": "8wrlyOsjCaJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0e504d-3f7b-4a21-a83a-2c8abbf991c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll instantiate a DataGenerator, which will normalize the train and test datasets, and will provide data augmentation during training:"
      ],
      "metadata": {
        "id": "4wUoT2jBCos1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)\n",
        "\n",
        "# Apply z-normalization on the training set\n",
        "data_generator.fit(X_train)\n",
        "\n",
        "# Standardize the validation set\n",
        "X_validation = data_generator.standardize(X_validation.astype('float32'))"
      ],
      "metadata": {
        "id": "Nc5QRbi5CxBz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll define the CNN model:"
      ],
      "metadata": {
        "id": "MpDra_dnC05b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "\n",
        "model = Sequential(layers=[\n",
        "    Conv2D(32, (3, 3),\n",
        "           padding='same',\n",
        "           input_shape=X_train.shape[1:]),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "5ZjHhpfIC23L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll define the optimization parameters:"
      ],
      "metadata": {
        "id": "9rb9N7AOC60z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfQH4wiZC9zj",
        "outputId": "73841c5f-ef3e-4156-ad76-8e6b71ac9957"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 6, 6, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293,930\n",
            "Trainable params: 293,034\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we'll run the training and evaluation:"
      ],
      "metadata": {
        "id": "1_7t7qVnDAt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "model.fit(\n",
        "    x=data_generator.flow(x=X_train,\n",
        "                          y=Y_train,\n",
        "                          batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=(X_validation, Y_validation),\n",
        "    workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LguIGCzcDFPc",
        "outputId": "edb8e0be-8a36-4d44-9317-5fee1baa7260"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 24s 15ms/step - loss: 1.6952 - accuracy: 0.3947 - val_loss: 1.2756 - val_accuracy: 0.5448\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 1.1976 - accuracy: 0.5690 - val_loss: 1.0338 - val_accuracy: 0.6277\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 1.0242 - accuracy: 0.6331 - val_loss: 1.0183 - val_accuracy: 0.6390\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.9303 - accuracy: 0.6701 - val_loss: 0.8112 - val_accuracy: 0.7104\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.8655 - accuracy: 0.6934 - val_loss: 0.7536 - val_accuracy: 0.7333\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.8158 - accuracy: 0.7120 - val_loss: 0.7287 - val_accuracy: 0.7382\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7801 - accuracy: 0.7237 - val_loss: 0.8272 - val_accuracy: 0.7143\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7421 - accuracy: 0.7385 - val_loss: 0.7201 - val_accuracy: 0.7508\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7190 - accuracy: 0.7466 - val_loss: 0.6989 - val_accuracy: 0.7481\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6922 - accuracy: 0.7569 - val_loss: 0.6116 - val_accuracy: 0.7810\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.6682 - accuracy: 0.7626 - val_loss: 0.6036 - val_accuracy: 0.7841\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6532 - accuracy: 0.7722 - val_loss: 0.6088 - val_accuracy: 0.7869\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6356 - accuracy: 0.7790 - val_loss: 0.6014 - val_accuracy: 0.7843\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6208 - accuracy: 0.7823 - val_loss: 0.5745 - val_accuracy: 0.7968\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6077 - accuracy: 0.7874 - val_loss: 0.5856 - val_accuracy: 0.7925\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5925 - accuracy: 0.7912 - val_loss: 0.5326 - val_accuracy: 0.8143\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5793 - accuracy: 0.7982 - val_loss: 0.5336 - val_accuracy: 0.8137\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5696 - accuracy: 0.7992 - val_loss: 0.5316 - val_accuracy: 0.8145\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5632 - accuracy: 0.8024 - val_loss: 0.5336 - val_accuracy: 0.8145\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5519 - accuracy: 0.8063 - val_loss: 0.5161 - val_accuracy: 0.8193\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5440 - accuracy: 0.8104 - val_loss: 0.5133 - val_accuracy: 0.8216\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5339 - accuracy: 0.8137 - val_loss: 0.4955 - val_accuracy: 0.8259\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5277 - accuracy: 0.8164 - val_loss: 0.5002 - val_accuracy: 0.8259\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5211 - accuracy: 0.8190 - val_loss: 0.4928 - val_accuracy: 0.8304\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5137 - accuracy: 0.8198 - val_loss: 0.4957 - val_accuracy: 0.8329\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5115 - accuracy: 0.8208 - val_loss: 0.4915 - val_accuracy: 0.8322\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5014 - accuracy: 0.8237 - val_loss: 0.4716 - val_accuracy: 0.8364\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4995 - accuracy: 0.8235 - val_loss: 0.4756 - val_accuracy: 0.8339\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4906 - accuracy: 0.8300 - val_loss: 0.4714 - val_accuracy: 0.8404\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4866 - accuracy: 0.8303 - val_loss: 0.4916 - val_accuracy: 0.8279\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4810 - accuracy: 0.8305 - val_loss: 0.4862 - val_accuracy: 0.8334\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4781 - accuracy: 0.8322 - val_loss: 0.4667 - val_accuracy: 0.8425\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4715 - accuracy: 0.8359 - val_loss: 0.4908 - val_accuracy: 0.8319\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4701 - accuracy: 0.8354 - val_loss: 0.4618 - val_accuracy: 0.8406\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4733 - accuracy: 0.8346 - val_loss: 0.4669 - val_accuracy: 0.8395\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4569 - accuracy: 0.8398 - val_loss: 0.4592 - val_accuracy: 0.8444\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4578 - accuracy: 0.8384 - val_loss: 0.4414 - val_accuracy: 0.8495\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4544 - accuracy: 0.8407 - val_loss: 0.4839 - val_accuracy: 0.8353\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4529 - accuracy: 0.8422 - val_loss: 0.4578 - val_accuracy: 0.8422\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4465 - accuracy: 0.8448 - val_loss: 0.4916 - val_accuracy: 0.8366\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4394 - accuracy: 0.8455 - val_loss: 0.4358 - val_accuracy: 0.8468\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4370 - accuracy: 0.8473 - val_loss: 0.4309 - val_accuracy: 0.8531\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4401 - accuracy: 0.8472 - val_loss: 0.4709 - val_accuracy: 0.8407\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4322 - accuracy: 0.8500 - val_loss: 0.4561 - val_accuracy: 0.8440\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4317 - accuracy: 0.8501 - val_loss: 0.4288 - val_accuracy: 0.8539\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4340 - accuracy: 0.8479 - val_loss: 0.4422 - val_accuracy: 0.8482\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.4271 - accuracy: 0.8509 - val_loss: 0.4340 - val_accuracy: 0.8508\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4238 - accuracy: 0.8505 - val_loss: 0.4294 - val_accuracy: 0.8540\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4249 - accuracy: 0.8499 - val_loss: 0.4386 - val_accuracy: 0.8521\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4235 - accuracy: 0.8521 - val_loss: 0.4356 - val_accuracy: 0.8539\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4192 - accuracy: 0.8532 - val_loss: 0.4272 - val_accuracy: 0.8574\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4197 - accuracy: 0.8511 - val_loss: 0.4360 - val_accuracy: 0.8559\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4144 - accuracy: 0.8567 - val_loss: 0.4464 - val_accuracy: 0.8493\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4159 - accuracy: 0.8553 - val_loss: 0.4226 - val_accuracy: 0.8591\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4081 - accuracy: 0.8561 - val_loss: 0.4223 - val_accuracy: 0.8557\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4083 - accuracy: 0.8560 - val_loss: 0.4363 - val_accuracy: 0.8567\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4068 - accuracy: 0.8576 - val_loss: 0.4395 - val_accuracy: 0.8544\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4034 - accuracy: 0.8561 - val_loss: 0.4348 - val_accuracy: 0.8550\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4044 - accuracy: 0.8577 - val_loss: 0.4383 - val_accuracy: 0.8528\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4050 - accuracy: 0.8587 - val_loss: 0.4606 - val_accuracy: 0.8481\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4011 - accuracy: 0.8584 - val_loss: 0.4279 - val_accuracy: 0.8560\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3961 - accuracy: 0.8605 - val_loss: 0.4381 - val_accuracy: 0.8528\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3949 - accuracy: 0.8626 - val_loss: 0.4676 - val_accuracy: 0.8457\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3899 - accuracy: 0.8631 - val_loss: 0.4305 - val_accuracy: 0.8547\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3897 - accuracy: 0.8634 - val_loss: 0.4305 - val_accuracy: 0.8574\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3879 - accuracy: 0.8651 - val_loss: 0.4342 - val_accuracy: 0.8520\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3920 - accuracy: 0.8635 - val_loss: 0.4162 - val_accuracy: 0.8611\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3824 - accuracy: 0.8649 - val_loss: 0.4614 - val_accuracy: 0.8478\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3880 - accuracy: 0.8636 - val_loss: 0.4095 - val_accuracy: 0.8600\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3880 - accuracy: 0.8632 - val_loss: 0.4380 - val_accuracy: 0.8550\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3827 - accuracy: 0.8657 - val_loss: 0.4275 - val_accuracy: 0.8570\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3851 - accuracy: 0.8659 - val_loss: 0.4208 - val_accuracy: 0.8599\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3805 - accuracy: 0.8657 - val_loss: 0.4196 - val_accuracy: 0.8607\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3763 - accuracy: 0.8663 - val_loss: 0.4378 - val_accuracy: 0.8528\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3771 - accuracy: 0.8670 - val_loss: 0.4338 - val_accuracy: 0.8572\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3753 - accuracy: 0.8678 - val_loss: 0.4090 - val_accuracy: 0.8640\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3714 - accuracy: 0.8678 - val_loss: 0.4115 - val_accuracy: 0.8626\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3664 - accuracy: 0.8698 - val_loss: 0.4123 - val_accuracy: 0.8630\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3721 - accuracy: 0.8684 - val_loss: 0.4131 - val_accuracy: 0.8643\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3693 - accuracy: 0.8693 - val_loss: 0.4256 - val_accuracy: 0.8591\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3686 - accuracy: 0.8710 - val_loss: 0.4110 - val_accuracy: 0.8606\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3667 - accuracy: 0.8706 - val_loss: 0.4277 - val_accuracy: 0.8564\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3615 - accuracy: 0.8718 - val_loss: 0.4347 - val_accuracy: 0.8573\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3708 - accuracy: 0.8691 - val_loss: 0.4035 - val_accuracy: 0.8644\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3639 - accuracy: 0.8717 - val_loss: 0.4442 - val_accuracy: 0.8530\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3661 - accuracy: 0.8698 - val_loss: 0.4153 - val_accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3648 - accuracy: 0.8714 - val_loss: 0.4105 - val_accuracy: 0.8639\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3568 - accuracy: 0.8731 - val_loss: 0.4024 - val_accuracy: 0.8667\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3596 - accuracy: 0.8729 - val_loss: 0.4129 - val_accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3576 - accuracy: 0.8726 - val_loss: 0.4073 - val_accuracy: 0.8646\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3548 - accuracy: 0.8742 - val_loss: 0.4106 - val_accuracy: 0.8617\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3562 - accuracy: 0.8732 - val_loss: 0.4101 - val_accuracy: 0.8623\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3575 - accuracy: 0.8723 - val_loss: 0.4156 - val_accuracy: 0.8621\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3518 - accuracy: 0.8760 - val_loss: 0.4129 - val_accuracy: 0.8599\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3517 - accuracy: 0.8759 - val_loss: 0.3981 - val_accuracy: 0.8688\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3558 - accuracy: 0.8747 - val_loss: 0.3994 - val_accuracy: 0.8649\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3520 - accuracy: 0.8745 - val_loss: 0.4182 - val_accuracy: 0.8596\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3541 - accuracy: 0.8743 - val_loss: 0.4091 - val_accuracy: 0.8654\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3561 - accuracy: 0.8722 - val_loss: 0.4202 - val_accuracy: 0.8596\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3495 - accuracy: 0.8756 - val_loss: 0.4253 - val_accuracy: 0.8585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a80077df0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}