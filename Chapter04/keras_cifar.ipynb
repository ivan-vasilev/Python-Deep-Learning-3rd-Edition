{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "We'll download the dataset first:"
   ],
   "metadata": {
    "id": "-h2cwJZ4COZg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(X_train, Y_train), (X_validation, Y_validation) = \\\n",
    "    keras.datasets.cifar10.load_data()\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_validation = keras.utils.to_categorical(Y_validation, 10)"
   ],
   "metadata": {
    "id": "8wrlyOsjCaJI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9ebc4e61-11d6-464a-ab19-b07073908694"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 14s 0us/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll instantiate a DataGenerator, which will normalize the train and test datasets, and will provide data augmentation during training:"
   ],
   "metadata": {
    "id": "4wUoT2jBCos1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Apply z-normalization on the training set\n",
    "data_generator.fit(X_train)\n",
    "\n",
    "# Standardize the validation set\n",
    "X_validation = data_generator.standardize(X_validation.astype('float32'))"
   ],
   "metadata": {
    "id": "Nc5QRbi5CxBz"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we'll define the CNN model:"
   ],
   "metadata": {
    "id": "MpDra_dnC05b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential(layers=[\n",
    "    layers.Conv2D(32, (3, 3),\n",
    "                  padding='same',\n",
    "                  input_shape=X_train.shape[1:]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.Conv2D(32, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.Conv2D(128, (3, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('gelu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "id": "5ZjHhpfIC23L"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll define the optimization parameters:"
   ],
   "metadata": {
    "id": "9rb9N7AOC60z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfQH4wiZC9zj",
    "outputId": "d9057d26-d2ab-4a8d-a054-8d6a9e94ec54"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6, 6, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293,930\n",
      "Trainable params: 293,034\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we'll run the training and evaluation:"
   ],
   "metadata": {
    "id": "1_7t7qVnDAt8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 50\n",
    "\n",
    "model.fit(\n",
    "    x=data_generator.flow(x=X_train,\n",
    "                          y=Y_train,\n",
    "                          batch_size=batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validation, Y_validation),\n",
    "    workers=4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LguIGCzcDFPc",
    "outputId": "53ba793c-c1f6-44c7-b0a0-898f2bc155c9"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 24s 16ms/step - loss: 1.6647 - accuracy: 0.4083 - val_loss: 1.2007 - val_accuracy: 0.5581\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 1.2007 - accuracy: 0.5688 - val_loss: 1.0213 - val_accuracy: 0.6286\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 1.0357 - accuracy: 0.6273 - val_loss: 0.8928 - val_accuracy: 0.6804\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.9370 - accuracy: 0.6658 - val_loss: 0.9065 - val_accuracy: 0.6760\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.8691 - accuracy: 0.6937 - val_loss: 0.7831 - val_accuracy: 0.7200\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.8132 - accuracy: 0.7108 - val_loss: 0.7412 - val_accuracy: 0.7422\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.7774 - accuracy: 0.7272 - val_loss: 0.7153 - val_accuracy: 0.7469\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7438 - accuracy: 0.7389 - val_loss: 0.6700 - val_accuracy: 0.7612\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7178 - accuracy: 0.7472 - val_loss: 0.6429 - val_accuracy: 0.7739\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6847 - accuracy: 0.7592 - val_loss: 0.6546 - val_accuracy: 0.7664\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6645 - accuracy: 0.7672 - val_loss: 0.6640 - val_accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6455 - accuracy: 0.7726 - val_loss: 0.6166 - val_accuracy: 0.7868\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6332 - accuracy: 0.7791 - val_loss: 0.5914 - val_accuracy: 0.7938\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6137 - accuracy: 0.7850 - val_loss: 0.5634 - val_accuracy: 0.8017\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6006 - accuracy: 0.7890 - val_loss: 0.6308 - val_accuracy: 0.7817\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5832 - accuracy: 0.7942 - val_loss: 0.5546 - val_accuracy: 0.8040\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5776 - accuracy: 0.7975 - val_loss: 0.5215 - val_accuracy: 0.8170\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5644 - accuracy: 0.8044 - val_loss: 0.5303 - val_accuracy: 0.8150\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5520 - accuracy: 0.8070 - val_loss: 0.5263 - val_accuracy: 0.8184\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5467 - accuracy: 0.8099 - val_loss: 0.5434 - val_accuracy: 0.8111\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5389 - accuracy: 0.8121 - val_loss: 0.5033 - val_accuracy: 0.8269\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5310 - accuracy: 0.8128 - val_loss: 0.5009 - val_accuracy: 0.8262\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5228 - accuracy: 0.8176 - val_loss: 0.4938 - val_accuracy: 0.8313\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5129 - accuracy: 0.8210 - val_loss: 0.5158 - val_accuracy: 0.8261\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5109 - accuracy: 0.8221 - val_loss: 0.5277 - val_accuracy: 0.8212\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.5001 - accuracy: 0.8255 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4986 - accuracy: 0.8251 - val_loss: 0.4939 - val_accuracy: 0.8295\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4878 - accuracy: 0.8278 - val_loss: 0.4573 - val_accuracy: 0.8463\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4890 - accuracy: 0.8278 - val_loss: 0.4666 - val_accuracy: 0.8399\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4828 - accuracy: 0.8318 - val_loss: 0.4627 - val_accuracy: 0.8411\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4752 - accuracy: 0.8333 - val_loss: 0.4651 - val_accuracy: 0.8392\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4745 - accuracy: 0.8357 - val_loss: 0.4755 - val_accuracy: 0.8369\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4685 - accuracy: 0.8350 - val_loss: 0.4699 - val_accuracy: 0.8406\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4669 - accuracy: 0.8357 - val_loss: 0.4662 - val_accuracy: 0.8402\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4583 - accuracy: 0.8393 - val_loss: 0.4406 - val_accuracy: 0.8496\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4533 - accuracy: 0.8409 - val_loss: 0.4412 - val_accuracy: 0.8480\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4538 - accuracy: 0.8411 - val_loss: 0.4524 - val_accuracy: 0.8484\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4408 - accuracy: 0.8454 - val_loss: 0.4575 - val_accuracy: 0.8404\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4499 - accuracy: 0.8414 - val_loss: 0.4483 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4389 - accuracy: 0.8455 - val_loss: 0.4581 - val_accuracy: 0.8421\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4349 - accuracy: 0.8482 - val_loss: 0.4439 - val_accuracy: 0.8465\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4386 - accuracy: 0.8461 - val_loss: 0.4573 - val_accuracy: 0.8449\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4317 - accuracy: 0.8487 - val_loss: 0.4284 - val_accuracy: 0.8545\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4284 - accuracy: 0.8509 - val_loss: 0.4352 - val_accuracy: 0.8531\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4291 - accuracy: 0.8510 - val_loss: 0.4271 - val_accuracy: 0.8570\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4223 - accuracy: 0.8521 - val_loss: 0.4476 - val_accuracy: 0.8515\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4188 - accuracy: 0.8534 - val_loss: 0.4434 - val_accuracy: 0.8482\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4156 - accuracy: 0.8542 - val_loss: 0.4392 - val_accuracy: 0.8491\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.4181 - accuracy: 0.8529 - val_loss: 0.4483 - val_accuracy: 0.8445\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4132 - accuracy: 0.8559 - val_loss: 0.4227 - val_accuracy: 0.8556\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4135 - accuracy: 0.8537 - val_loss: 0.4242 - val_accuracy: 0.8537\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4080 - accuracy: 0.8554 - val_loss: 0.4194 - val_accuracy: 0.8577\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4030 - accuracy: 0.8581 - val_loss: 0.4312 - val_accuracy: 0.8560\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4097 - accuracy: 0.8572 - val_loss: 0.4132 - val_accuracy: 0.8586\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4088 - accuracy: 0.8578 - val_loss: 0.4243 - val_accuracy: 0.8601\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4016 - accuracy: 0.8586 - val_loss: 0.4133 - val_accuracy: 0.8598\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4020 - accuracy: 0.8587 - val_loss: 0.4266 - val_accuracy: 0.8587\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3957 - accuracy: 0.8625 - val_loss: 0.4206 - val_accuracy: 0.8575\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3976 - accuracy: 0.8589 - val_loss: 0.4350 - val_accuracy: 0.8574\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3940 - accuracy: 0.8614 - val_loss: 0.4131 - val_accuracy: 0.8634\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3955 - accuracy: 0.8620 - val_loss: 0.4184 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3910 - accuracy: 0.8620 - val_loss: 0.4101 - val_accuracy: 0.8593\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3919 - accuracy: 0.8620 - val_loss: 0.4212 - val_accuracy: 0.8604\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3864 - accuracy: 0.8651 - val_loss: 0.4274 - val_accuracy: 0.8596\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3901 - accuracy: 0.8628 - val_loss: 0.4133 - val_accuracy: 0.8623\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3866 - accuracy: 0.8641 - val_loss: 0.4114 - val_accuracy: 0.8654\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3862 - accuracy: 0.8646 - val_loss: 0.4034 - val_accuracy: 0.8680\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3853 - accuracy: 0.8658 - val_loss: 0.4136 - val_accuracy: 0.8577\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3775 - accuracy: 0.8686 - val_loss: 0.4185 - val_accuracy: 0.8604\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3852 - accuracy: 0.8636 - val_loss: 0.4149 - val_accuracy: 0.8607\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3771 - accuracy: 0.8661 - val_loss: 0.4324 - val_accuracy: 0.8558\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.3793 - accuracy: 0.8676 - val_loss: 0.4193 - val_accuracy: 0.8596\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3794 - accuracy: 0.8667 - val_loss: 0.4187 - val_accuracy: 0.8631\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3713 - accuracy: 0.8694 - val_loss: 0.3961 - val_accuracy: 0.8690\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3773 - accuracy: 0.8675 - val_loss: 0.3977 - val_accuracy: 0.8695\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3700 - accuracy: 0.8689 - val_loss: 0.4084 - val_accuracy: 0.8614\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3707 - accuracy: 0.8688 - val_loss: 0.4088 - val_accuracy: 0.8636\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3713 - accuracy: 0.8686 - val_loss: 0.4162 - val_accuracy: 0.8594\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3745 - accuracy: 0.8679 - val_loss: 0.4057 - val_accuracy: 0.8643\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3731 - accuracy: 0.8665 - val_loss: 0.4229 - val_accuracy: 0.8613\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3663 - accuracy: 0.8718 - val_loss: 0.4249 - val_accuracy: 0.8606\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3674 - accuracy: 0.8709 - val_loss: 0.4135 - val_accuracy: 0.8628\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3622 - accuracy: 0.8743 - val_loss: 0.4017 - val_accuracy: 0.8692\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3633 - accuracy: 0.8713 - val_loss: 0.4047 - val_accuracy: 0.8644\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3586 - accuracy: 0.8744 - val_loss: 0.4082 - val_accuracy: 0.8617\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3576 - accuracy: 0.8736 - val_loss: 0.4268 - val_accuracy: 0.8570\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3627 - accuracy: 0.8724 - val_loss: 0.4058 - val_accuracy: 0.8662\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3593 - accuracy: 0.8737 - val_loss: 0.4074 - val_accuracy: 0.8632\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3559 - accuracy: 0.8731 - val_loss: 0.4195 - val_accuracy: 0.8605\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3566 - accuracy: 0.8740 - val_loss: 0.4087 - val_accuracy: 0.8656\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3558 - accuracy: 0.8728 - val_loss: 0.4087 - val_accuracy: 0.8648\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3537 - accuracy: 0.8761 - val_loss: 0.4266 - val_accuracy: 0.8570\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.3543 - accuracy: 0.8748 - val_loss: 0.4098 - val_accuracy: 0.8655\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.3508 - accuracy: 0.8763 - val_loss: 0.3963 - val_accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.3469 - accuracy: 0.8780 - val_loss: 0.4127 - val_accuracy: 0.8610\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3539 - accuracy: 0.8750 - val_loss: 0.4150 - val_accuracy: 0.8632\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.3938 - val_accuracy: 0.8679\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3451 - accuracy: 0.8779 - val_loss: 0.4064 - val_accuracy: 0.8666\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3474 - accuracy: 0.8770 - val_loss: 0.3959 - val_accuracy: 0.8726\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3476 - accuracy: 0.8772 - val_loss: 0.3952 - val_accuracy: 0.8677\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9ca3d9eac0>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  }
 ]
}
