{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll download the dataset first:"
      ],
      "metadata": {
        "id": "-h2cwJZ4COZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train, Y_train), (X_validation, Y_validation) = cifar10.load_data()\n",
        "\n",
        "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
        "Y_validation = keras.utils.to_categorical(Y_validation, 10)"
      ],
      "metadata": {
        "id": "8wrlyOsjCaJI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll instantiate a DataGenerator, which will normalize the train and test datasets, and will provide data augmentation during training:"
      ],
      "metadata": {
        "id": "4wUoT2jBCos1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Apply z-normalization on the training set\n",
        "data_generator.fit(X_train)\n",
        "\n",
        "# Standardize the validation set\n",
        "X_validation = data_generator.standardize(X_validation.astype('float32'))"
      ],
      "metadata": {
        "id": "Nc5QRbi5CxBz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll define the CNN model:"
      ],
      "metadata": {
        "id": "MpDra_dnC05b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "\n",
        "model = Sequential(layers=[\n",
        "    Conv2D(32, (3, 3),\n",
        "           padding='same',\n",
        "           input_shape=X_train.shape[1:]),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "5ZjHhpfIC23L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll define the optimization parameters:"
      ],
      "metadata": {
        "id": "9rb9N7AOC60z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfQH4wiZC9zj",
        "outputId": "b2f3ace8-4f3c-4545-b518-6de192a9699b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 6, 6, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293,930\n",
            "Trainable params: 293,034\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we'll run the training and evaluation:"
      ],
      "metadata": {
        "id": "1_7t7qVnDAt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "model.fit(\n",
        "    x=data_generator.flow(x=X_train,\n",
        "                          y=Y_train,\n",
        "                          batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=(X_validation, Y_validation),\n",
        "    workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LguIGCzcDFPc",
        "outputId": "706a542d-9c56-4cf6-b0bb-4166e3c03f44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 48s 44ms/step - loss: 1.8719 - accuracy: 0.3366 - val_loss: 1.8343 - val_accuracy: 0.3659\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 46s 46ms/step - loss: 1.5062 - accuracy: 0.4576 - val_loss: 1.4372 - val_accuracy: 0.4911\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 45s 45ms/step - loss: 1.3326 - accuracy: 0.5243 - val_loss: 1.3803 - val_accuracy: 0.5374\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 45s 45ms/step - loss: 1.2309 - accuracy: 0.5651 - val_loss: 1.2723 - val_accuracy: 0.5633\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 45s 45ms/step - loss: 1.1577 - accuracy: 0.5904 - val_loss: 1.2233 - val_accuracy: 0.5912\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 46s 46ms/step - loss: 1.1059 - accuracy: 0.6117 - val_loss: 1.1585 - val_accuracy: 0.6079\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 46s 46ms/step - loss: 1.0636 - accuracy: 0.6268 - val_loss: 1.0317 - val_accuracy: 0.6511\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 1.0219 - accuracy: 0.6445 - val_loss: 0.9626 - val_accuracy: 0.6704\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.9936 - accuracy: 0.6552 - val_loss: 0.9365 - val_accuracy: 0.6801\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 44s 43ms/step - loss: 0.9681 - accuracy: 0.6617 - val_loss: 0.8814 - val_accuracy: 0.6918\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.9430 - accuracy: 0.6724 - val_loss: 0.9217 - val_accuracy: 0.6826\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.9302 - accuracy: 0.6782 - val_loss: 0.9126 - val_accuracy: 0.6984\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.9019 - accuracy: 0.6876 - val_loss: 0.8534 - val_accuracy: 0.7073\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.8890 - accuracy: 0.6917 - val_loss: 0.8890 - val_accuracy: 0.7005\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.8708 - accuracy: 0.6960 - val_loss: 0.7595 - val_accuracy: 0.7384\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.8581 - accuracy: 0.7002 - val_loss: 0.8119 - val_accuracy: 0.7254\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.8469 - accuracy: 0.7072 - val_loss: 0.8584 - val_accuracy: 0.7129\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 0.8368 - accuracy: 0.7083 - val_loss: 0.8388 - val_accuracy: 0.7185\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 0.8297 - accuracy: 0.7124 - val_loss: 0.7942 - val_accuracy: 0.7322\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.8188 - accuracy: 0.7160 - val_loss: 0.7972 - val_accuracy: 0.7337\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.8101 - accuracy: 0.7192 - val_loss: 0.8020 - val_accuracy: 0.7310\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 0.7995 - accuracy: 0.7247 - val_loss: 0.8244 - val_accuracy: 0.7239\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7939 - accuracy: 0.7269 - val_loss: 0.7934 - val_accuracy: 0.7328\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7866 - accuracy: 0.7281 - val_loss: 0.7380 - val_accuracy: 0.7508\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7806 - accuracy: 0.7309 - val_loss: 0.6337 - val_accuracy: 0.7824\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7755 - accuracy: 0.7324 - val_loss: 0.7263 - val_accuracy: 0.7608\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7726 - accuracy: 0.7314 - val_loss: 0.7724 - val_accuracy: 0.7458\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7599 - accuracy: 0.7368 - val_loss: 0.7790 - val_accuracy: 0.7448\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7541 - accuracy: 0.7405 - val_loss: 0.7176 - val_accuracy: 0.7577\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7523 - accuracy: 0.7402 - val_loss: 0.6927 - val_accuracy: 0.7661\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7461 - accuracy: 0.7408 - val_loss: 0.7009 - val_accuracy: 0.7655\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7408 - accuracy: 0.7442 - val_loss: 0.7154 - val_accuracy: 0.7580\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7394 - accuracy: 0.7436 - val_loss: 0.6663 - val_accuracy: 0.7743\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7334 - accuracy: 0.7464 - val_loss: 0.6705 - val_accuracy: 0.7736\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7319 - accuracy: 0.7469 - val_loss: 0.6738 - val_accuracy: 0.7753\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7215 - accuracy: 0.7508 - val_loss: 0.7154 - val_accuracy: 0.7603\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 0.7205 - accuracy: 0.7520 - val_loss: 0.6862 - val_accuracy: 0.7721\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 43s 43ms/step - loss: 0.7220 - accuracy: 0.7521 - val_loss: 0.6476 - val_accuracy: 0.7802\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7171 - accuracy: 0.7524 - val_loss: 0.6239 - val_accuracy: 0.7940\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.7144 - accuracy: 0.7513 - val_loss: 0.6893 - val_accuracy: 0.7750\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7048 - accuracy: 0.7568 - val_loss: 0.7414 - val_accuracy: 0.7526\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7010 - accuracy: 0.7583 - val_loss: 0.6201 - val_accuracy: 0.7936\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.7037 - accuracy: 0.7565 - val_loss: 0.6292 - val_accuracy: 0.7906\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 0.7043 - accuracy: 0.7572 - val_loss: 0.6284 - val_accuracy: 0.7886\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6934 - accuracy: 0.7615 - val_loss: 0.7115 - val_accuracy: 0.7654\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 0.6979 - accuracy: 0.7585 - val_loss: 0.6657 - val_accuracy: 0.7737\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6851 - accuracy: 0.7610 - val_loss: 0.6102 - val_accuracy: 0.7965\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6903 - accuracy: 0.7614 - val_loss: 0.6550 - val_accuracy: 0.7845\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 0.6853 - accuracy: 0.7644 - val_loss: 0.7097 - val_accuracy: 0.7634\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6838 - accuracy: 0.7636 - val_loss: 0.6933 - val_accuracy: 0.7741\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6829 - accuracy: 0.7659 - val_loss: 0.6393 - val_accuracy: 0.7890\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6805 - accuracy: 0.7657 - val_loss: 0.6518 - val_accuracy: 0.7862\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6823 - accuracy: 0.7631 - val_loss: 0.6331 - val_accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6790 - accuracy: 0.7641 - val_loss: 0.6932 - val_accuracy: 0.7718\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6771 - accuracy: 0.7663 - val_loss: 0.6841 - val_accuracy: 0.7738\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 0.6677 - accuracy: 0.7661 - val_loss: 0.6146 - val_accuracy: 0.7939\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 40s 39ms/step - loss: 0.6746 - accuracy: 0.7686 - val_loss: 0.6290 - val_accuracy: 0.7893\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6626 - accuracy: 0.7710 - val_loss: 0.6316 - val_accuracy: 0.7905\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6629 - accuracy: 0.7715 - val_loss: 0.6669 - val_accuracy: 0.7799\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6619 - accuracy: 0.7712 - val_loss: 0.6233 - val_accuracy: 0.7915\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6619 - accuracy: 0.7700 - val_loss: 0.6236 - val_accuracy: 0.7915\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6566 - accuracy: 0.7713 - val_loss: 0.6611 - val_accuracy: 0.7849\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6623 - accuracy: 0.7713 - val_loss: 0.6025 - val_accuracy: 0.7986\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6568 - accuracy: 0.7717 - val_loss: 0.6418 - val_accuracy: 0.7828\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6547 - accuracy: 0.7730 - val_loss: 0.6258 - val_accuracy: 0.7891\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 0.6504 - accuracy: 0.7752 - val_loss: 0.6078 - val_accuracy: 0.7950\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6496 - accuracy: 0.7764 - val_loss: 0.5842 - val_accuracy: 0.8056\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6452 - accuracy: 0.7778 - val_loss: 0.5926 - val_accuracy: 0.8030\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6461 - accuracy: 0.7763 - val_loss: 0.5900 - val_accuracy: 0.8022\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6479 - accuracy: 0.7751 - val_loss: 0.6005 - val_accuracy: 0.7975\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6419 - accuracy: 0.7816 - val_loss: 0.5918 - val_accuracy: 0.8026\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6377 - accuracy: 0.7790 - val_loss: 0.6306 - val_accuracy: 0.7953\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6443 - accuracy: 0.7753 - val_loss: 0.6750 - val_accuracy: 0.7807\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6432 - accuracy: 0.7784 - val_loss: 0.5877 - val_accuracy: 0.8087\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 41s 40ms/step - loss: 0.6402 - accuracy: 0.7780 - val_loss: 0.6031 - val_accuracy: 0.8007\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6453 - accuracy: 0.7790 - val_loss: 0.6131 - val_accuracy: 0.8015\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6303 - accuracy: 0.7812 - val_loss: 0.6574 - val_accuracy: 0.7832\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6344 - accuracy: 0.7822 - val_loss: 0.5766 - val_accuracy: 0.8091\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6383 - accuracy: 0.7788 - val_loss: 0.5806 - val_accuracy: 0.8055\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6307 - accuracy: 0.7810 - val_loss: 0.6208 - val_accuracy: 0.7998\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6268 - accuracy: 0.7846 - val_loss: 0.5392 - val_accuracy: 0.8198\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6281 - accuracy: 0.7836 - val_loss: 0.6144 - val_accuracy: 0.7954\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6280 - accuracy: 0.7841 - val_loss: 0.6400 - val_accuracy: 0.7909\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6293 - accuracy: 0.7812 - val_loss: 0.5618 - val_accuracy: 0.8158\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6257 - accuracy: 0.7839 - val_loss: 0.6664 - val_accuracy: 0.7849\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6310 - accuracy: 0.7809 - val_loss: 0.5850 - val_accuracy: 0.8086\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6276 - accuracy: 0.7830 - val_loss: 0.5957 - val_accuracy: 0.8023\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6211 - accuracy: 0.7853 - val_loss: 0.5844 - val_accuracy: 0.8084\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 41s 41ms/step - loss: 0.6202 - accuracy: 0.7861 - val_loss: 0.6680 - val_accuracy: 0.7815\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6167 - accuracy: 0.7859 - val_loss: 0.5902 - val_accuracy: 0.8037\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6179 - accuracy: 0.7872 - val_loss: 0.6171 - val_accuracy: 0.7979\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6204 - accuracy: 0.7878 - val_loss: 0.6000 - val_accuracy: 0.8049\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6222 - accuracy: 0.7850 - val_loss: 0.5828 - val_accuracy: 0.8052\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6186 - accuracy: 0.7858 - val_loss: 0.6468 - val_accuracy: 0.7908\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6240 - accuracy: 0.7834 - val_loss: 0.5847 - val_accuracy: 0.8081\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6143 - accuracy: 0.7877 - val_loss: 0.5887 - val_accuracy: 0.8089\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 42s 41ms/step - loss: 0.6169 - accuracy: 0.7862 - val_loss: 0.5904 - val_accuracy: 0.8057\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 39s 39ms/step - loss: 0.6196 - accuracy: 0.7890 - val_loss: 0.6247 - val_accuracy: 0.7987\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6095 - accuracy: 0.7874 - val_loss: 0.5650 - val_accuracy: 0.8107\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 40s 40ms/step - loss: 0.6149 - accuracy: 0.7847 - val_loss: 0.6307 - val_accuracy: 0.7963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc960181400>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}