{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by selecting a device:"
      ],
      "metadata": {
        "id": "DXFIL_LeakGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CBrYKNYlF-Gr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll load and flatten the dataset:"
      ],
      "metadata": {
        "id": "e2DAL9cVGHh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    transform=Compose(\n",
        "        [ToTensor(),\n",
        "         Lambda(lambda x: torch.flatten(x))]),\n",
        "    download=True,\n",
        ")\n",
        "validation_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    transform=Compose(\n",
        "        [ToTensor(),\n",
        "         Lambda(lambda x: torch.flatten(x))]),\n",
        ")"
      ],
      "metadata": {
        "id": "VHgZfmykao0F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create the data loaders:"
      ],
      "metadata": {
        "id": "ZB9h_u4najgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=100,\n",
        "    shuffle=True)\n",
        "\n",
        "validation_loader = DataLoader(\n",
        "    validation_data,\n",
        "    batch_size=100,\n",
        "    shuffle=True)"
      ],
      "metadata": {
        "id": "E2TgH3Mta2OM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll define the NN:"
      ],
      "metadata": {
        "id": "DA2RvMEYa7mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "hidden_units = 100\n",
        "classes = 10\n",
        "\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(28 * 28, hidden_units),\n",
        "    torch.nn.BatchNorm1d(hidden_units),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(hidden_units, classes),\n",
        ")"
      ],
      "metadata": {
        "id": "PPp1ZbhVa9t-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll implement the `train_model` function:"
      ],
      "metadata": {
        "id": "-Kg-EZGxGVpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, cost_function, optimizer, data_loader):\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    current_loss = 0.0\n",
        "    current_acc = 0\n",
        "\n",
        "    # iterate over the training data\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        # send the input/labels to the GPU\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            loss = cost_function(outputs, labels)\n",
        "\n",
        "            # backward\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        current_loss += loss.item() * inputs.size(0)\n",
        "        current_acc += torch.sum(predictions == labels.data)\n",
        "\n",
        "    total_loss = current_loss / len(data_loader.dataset)\n",
        "    total_acc = current_acc.double() / len(data_loader.dataset)\n",
        "\n",
        "    print('Train Loss: {:.4f}; Accuracy: {:.4f}'.format(total_loss, total_acc))"
      ],
      "metadata": {
        "id": "ABoifiKIGaeC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll implement the `test_model` function:"
      ],
      "metadata": {
        "id": "N7rVHHVeGh_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, cost_function, data_loader):\n",
        "    # set model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    current_loss = 0.0\n",
        "    current_acc = 0\n",
        "\n",
        "    # iterate over  the validation data\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        # send the input/labels to the GPU\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            loss = cost_function(outputs, labels)\n",
        "\n",
        "        # statistics\n",
        "        current_loss += loss.item() * inputs.size(0)\n",
        "        current_acc += torch.sum(predictions == labels.data)\n",
        "\n",
        "    total_loss = current_loss / len(data_loader.dataset)\n",
        "    total_acc = current_acc.double() / len(data_loader.dataset)\n",
        "\n",
        "    print('Test Loss: {:.4f}; Accuracy: {:.4f}'.format(total_loss, total_acc))\n",
        "\n",
        "    return total_loss, total_acc"
      ],
      "metadata": {
        "id": "ZFiY0zO1GlVz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's define the optimizer:"
      ],
      "metadata": {
        "id": "PceFD0l8bAWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "LspmitnYbC_o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll train for 20 epochs:"
      ],
      "metadata": {
        "id": "v884fwfabE64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
        "    train_model(net, cost_func, optimizer, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmT91JnnbITh",
        "outputId": "9e36a2be-56a7-436a-c624-f514dee5ad5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Loss: 0.3272; Accuracy: 0.9175\n",
            "Epoch 2/20\n",
            "Train Loss: 0.1421; Accuracy: 0.9604\n",
            "Epoch 3/20\n",
            "Train Loss: 0.0999; Accuracy: 0.9721\n",
            "Epoch 4/20\n",
            "Train Loss: 0.0760; Accuracy: 0.9790\n",
            "Epoch 5/20\n",
            "Train Loss: 0.0611; Accuracy: 0.9828\n",
            "Epoch 6/20\n",
            "Train Loss: 0.0495; Accuracy: 0.9863\n",
            "Epoch 7/20\n",
            "Train Loss: 0.0422; Accuracy: 0.9879\n",
            "Epoch 8/20\n",
            "Train Loss: 0.0358; Accuracy: 0.9898\n",
            "Epoch 9/20\n",
            "Train Loss: 0.0309; Accuracy: 0.9909\n",
            "Epoch 10/20\n",
            "Train Loss: 0.0262; Accuracy: 0.9929\n",
            "Epoch 11/20\n",
            "Train Loss: 0.0228; Accuracy: 0.9936\n",
            "Epoch 12/20\n",
            "Train Loss: 0.0201; Accuracy: 0.9948\n",
            "Epoch 13/20\n",
            "Train Loss: 0.0182; Accuracy: 0.9950\n",
            "Epoch 14/20\n",
            "Train Loss: 0.0174; Accuracy: 0.9952\n",
            "Epoch 15/20\n",
            "Train Loss: 0.0160; Accuracy: 0.9954\n",
            "Epoch 16/20\n",
            "Train Loss: 0.0131; Accuracy: 0.9967\n",
            "Epoch 17/20\n",
            "Train Loss: 0.0121; Accuracy: 0.9968\n",
            "Epoch 18/20\n",
            "Train Loss: 0.0113; Accuracy: 0.9968\n",
            "Epoch 19/20\n",
            "Train Loss: 0.0107; Accuracy: 0.9971\n",
            "Epoch 20/20\n",
            "Train Loss: 0.0101; Accuracy: 0.9974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we'll run the evaluation:"
      ],
      "metadata": {
        "id": "1Mri_nHjb2qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(net, cost_func, validation_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbkdnRhgb50j",
        "outputId": "15f52de8-1065-4b09-8476-48ec398f3613"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0886; Accuracy: 0.9772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.08855911538470536, tensor(0.9772, dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}